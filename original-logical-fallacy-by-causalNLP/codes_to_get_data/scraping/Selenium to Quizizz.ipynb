{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_url,test_name,grade,sentence, LFT=[],[],[],[],[]\n",
    "total_links = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def load_csv(csv_path):\n",
    "    global source_url,test_name,grade,sentence, LFT\n",
    "    datas = pd.read_csv(csv_path)\n",
    "    datas_array = np.array(datas)\n",
    "    source_url += datas_array[:,1].tolist()\n",
    "    test_name += datas_array[:,2].tolist()\n",
    "    grade += datas_array[:,3].tolist()\n",
    "    LFT += datas_array[:,4].tolist()\n",
    "    sentence += datas_array[:,5].tolist()\n",
    "\n",
    "load_csv('data.csv')\n",
    "load_csv('data233.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_links = list(set(source_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38278"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(source_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://quizizz.com/admin/quiz/5f589da2cf5b97001b513da7/logical-fallacies-practice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_answer(driver):\n",
    "    answer_button = driver.find_element_by_class_name('show-answers-btn')\n",
    "    button_status = answer_button.find_element_by_class_name('far').get_attribute('class')\n",
    "    if button_status == 'far fa-eye':\n",
    "        answer_button.click()\n",
    "open_answer(driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<selenium.webdriver.remote.webelement.WebElement (session=\"b5b04e78c28c6775582289370e6a547d\", element=\"ef01f861-0d58-48bd-b13e-73a7bf95a654\")>\n",
      "far fa-eye-slash\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['Q. Identify the logical fallacy committed.\\n\\nIt is ridiculous to have spent thousands of dollars to rescue those two whales trapped in the Arctic ice. Why, look at all the people trapped in jobs they don’t like.',\n",
       "  'Weak analogy'],\n",
       " ['Q. Identify the logical fallacy committed.\\n\\nPlagiarism is deceitful because it is dishonest.',\n",
       "  'Begging the question'],\n",
       " [\"Q. Identify the logical fallacy committed.\\n\\nWater fluoridation affects the brain. Citywide, student’s test scores began to drop five months after fluoridation began. The water fluoridation must have caused the student's test scores to drop.\",\n",
       "  'Post hoc'],\n",
       " ['Q. Identify the logical fallacy committed.\\n\\nI know three redheads who have terrible tempers, and since Annabel has red hair, I’ll bet she has a terrible temper too.',\n",
       "  'Hasty generalization'],\n",
       " ['Q. Identify the logical fallacy committed.\\n\\nYou support capital punishment just because you want an “eye for an eye,” but I have several good reasons to believe that capital punishment is fundamentally wrong…',\n",
       "  ''],\n",
       " ['Q. Identify the logical fallacy committed.\\n\\nWe can’t freeze the academic year because then students won’t graduate on time. Next thing you know most people will be unemployed and will resort to crime. The crime rate will skyrocket and society will collapse.',\n",
       "  'Slippery slope'],\n",
       " ['Q. Identify the logical fallacy committed.\\n\\nThe book \"Investing for Dummies\" really helped me understand my finances better. The book \"Chess for Dummies\" was written by the same author, was published by the same press, and costs about the same amount, so it would probably help me understand my finances as well.',\n",
       "  'Weak analogy'],\n",
       " ['Q. Identify the logical fallacy committed.\\n\\nLook, you are going to have to make up your mind. Either you decide that you can afford this stereo, or you decide you are going to do without music for a while',\n",
       "  ''],\n",
       " ['Q. Identify the logical fallacy committed.\\n\\nWe shouldn’t put her in jail even if she stole billions of pesos. She is already too old to be locked up.',\n",
       "  'Appeal to pity'],\n",
       " ['Q. Identify the logical fallacy committed.\\n\\nThere is a global recession and more people are becoming hungry and desperate. Crimes of theft and robbery have been increasing at an alarming rate lately. The only way to solve this problem is by reinstating the death penalty',\n",
       "  ''],\n",
       " ['Q. Identify the logical fallacy committed.\\n\\nThere is no concrete proof that Duterte himself is corrupt; therefore, he is an honest politician.',\n",
       "  'Appeal to ignorance'],\n",
       " ['Q. Identify the logical fallacy committed.\\n\\nFamous actors like Alex Gonzaga and Philip Salvador support Oplan Tokhang, so it must be an effective operation.',\n",
       "  'Appeal to authority'],\n",
       " ['Q. Identify the logical fallacy committed.\\n\\nWhy are you criticizing the Anti-Terror Law? Are you a terrorist?',\n",
       "  '']]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_single_driver(driver):\n",
    "    open_answer(driver)\n",
    "        \n",
    "    questions = driver.find_elements_by_class_name('question')\n",
    "    answer = []\n",
    "    for question in questions:\n",
    "        text = [i.text for i in question.find_elements_by_class_name('query')]\n",
    "        foptions = question.find_elements_by_class_name('text-only-option')\n",
    "        foptions = [i.text for i in foptions if i.find_element_by_class_name('option-marker').get_attribute('class') == 'option-marker true']\n",
    "        if (len(foptions)==0):\n",
    "            foptions = [i.text for i in question.find_elements_by_class_name('text')]\n",
    "        if len(text)==1 and len(foptions)>=1:\n",
    "            answer.append([text[0],' & '.join(foptions)])\n",
    "    \n",
    "    return answer\n",
    "    \n",
    "get_single_driver(driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://quizizz.com/admin/search/logical%20fallacies?sortBy=_score&grade=all&subject=All&langs=English&numQuestions=&duplicates=false&studentQuizzes=false&safeSearch=true&type=quiz,')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "504"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results=driver.find_element_by_class_name('search-results').find_elements_by_class_name('router-link')\n",
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the valid link\n",
    "links = [i.get_attribute('href')for i in results]\n",
    "def link_filter(link):\n",
    "    return ('https://quizizz.com/admin/' in link )\n",
    "links = [link for link in links if link_filter(link)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "203"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove duplicate links\n",
    "links = [i for i in links if not i in total_links]\n",
    "for link in links:\n",
    "    total_links.append(link)\n",
    "len(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(total_links)\n",
    "total_links_old = list(set(source_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "932"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llinks = [i for i in total_links if not i in total_links_old]\n",
    "len(llinks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "li, grades, names, ans = [], [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "li, grades, names, ans = [], [], [], []\n",
    "qwq = 0\n",
    "for link in llinks:\n",
    "    print(qwq)\n",
    "    qwq+=1\n",
    "    driver.get(link)\n",
    "    time.sleep(2)\n",
    "    new_ans = get_single_driver(driver)\n",
    "    ans.append(new_ans)\n",
    "    li.append([link]*len(new_ans))\n",
    "    grades.append(driver.find_elements_by_class_name('grades')[0].text)\n",
    "    names.append(driver.find_elements_by_class_name('quiz-name-text')[0].text)\n",
    "print(len(ans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source_url,test_name,grade,sentence, LFT=[],[],[],[],[]\n",
    "for i in range(556):\n",
    "    for j in ans[i]:\n",
    "        source_url.append(llinks[i])\n",
    "        test_name.append(names[i])\n",
    "        grade.append(grades[i])\n",
    "        sentence.append(j[0])\n",
    "        LFT.append(j[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "datas = pd.DataFrame({'source_url':source_url,\n",
    "                      'test_name':test_name,\n",
    "                      'grade':grade,\n",
    "                      'Logical Fallacy Types':LFT,\n",
    "                      'sentence':sentence\n",
    "                    })\n",
    "datas.to_csv('data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
